{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sh scripts/exps/expand_diff.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python classification/classificationAtExpanedM_Rock.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python classification/classificationAtM_Rock.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python fid/fid.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import AutoencoderKL\n",
    "vae = AutoencoderKL.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"vae\")\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-5)\n",
    "vae.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        images = batch['image'].to(device)\n",
    "        latents = vae.encode(images).latent_dist.sample()\n",
    "        recon_images = vae.decode(latents).sample()\n",
    "        recon_loss = torch.nn.functional.mse_loss(recon_images, images)\n",
    "        kl_loss = -0.5 * torch.sum(1 + vae.logvar - vae.mean.pow(2) - vae.logvar.exp())\n",
    "        loss = recon_loss + kl_weight * kl_loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "vae.save_pretrained(\"path/to/your_custom_vae\")\n",
    "from diffusers import StableDiffusionPipeline\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", vae=\"path/to/your_custom_vae\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classfication valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define paths\n",
    "# data_dir = \"data/m_rock/train\"\n",
    "data_dir = \"data/rock_minerals/train\"\n",
    "save_dir = \"figure\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset\n",
    "train_dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "# KFold cross-validation setup\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Model definitions\n",
    "models_dict = {\n",
    "    \"ResNet50\": models.resnet50,\n",
    "    \"ResNeXt-50\": models.resnext50_32x4d,\n",
    "    \"WideResNet-50\": models.wide_resnet50_2,\n",
    "    \"MobileNetv2\": models.mobilenet_v2\n",
    "}\n",
    "\n",
    "# Results storage\n",
    "results = []\n",
    "\n",
    "# Training and evaluation function\n",
    "def train_and_evaluate(model_name, model, train_loader, test_loader):\n",
    "    print(f\"Training {model_name}...\")\n",
    "    \n",
    "    # Initialize model, loss, and optimizer\n",
    "    model = model(num_classes=len(train_dataset.classes))  # Correct this line\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(all_labels, all_preds, target_names=train_dataset.classes, output_dict=True)\n",
    "    accuracy = report['accuracy']\n",
    "    recall = np.mean([v['recall'] for k, v in report.items() if k not in ('accuracy', 'macro avg', 'weighted avg')])\n",
    "    f1 = np.mean([v['f1-score'] for k, v in report.items() if k not in ('accuracy', 'macro avg', 'weighted avg')])\n",
    "\n",
    "    print(f\"{model_name} - Accuracy: {accuracy:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "\n",
    "    return accuracy, recall, f1\n",
    "\n",
    "# Cross-validation loop\n",
    "for model_name, model_fn in models_dict.items():\n",
    "    fold_results = []\n",
    "\n",
    "    # Perform KFold cross-validation\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
    "        print(f\"\\nFold {fold+1} - Model: {model_name}\")\n",
    "\n",
    "        # Create data loaders for the current fold\n",
    "        train_subset = Subset(train_dataset, train_idx)\n",
    "        val_subset = Subset(train_dataset, val_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Train and evaluate the model\n",
    "        accuracy, recall, f1 = train_and_evaluate(model_name, model_fn, train_loader, val_loader)\n",
    "        fold_results.append({\n",
    "            'Fold': fold + 1,\n",
    "            'Accuracy': accuracy,\n",
    "            'Recall': recall,\n",
    "            'F1-Score': f1\n",
    "        })\n",
    "\n",
    "    # Calculate average results for the model across all folds\n",
    "    avg_accuracy = np.mean([result['Accuracy'] for result in fold_results])\n",
    "    avg_recall = np.mean([result['Recall'] for result in fold_results])\n",
    "    avg_f1 = np.mean([result['F1-Score'] for result in fold_results])\n",
    "\n",
    "    print(f\"\\n{model_name} - Average Accuracy: {avg_accuracy:.4f}, Average Recall: {avg_recall:.4f}, Average F1-score: {avg_f1:.4f}\")\n",
    "\n",
    "    # Save fold results to the overall results list\n",
    "    for result in fold_results:\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Fold': result['Fold'],\n",
    "            'Accuracy': result['Accuracy'],\n",
    "            'Recall': result['Recall'],\n",
    "            'F1-Score': result['F1-Score']\n",
    "        })\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(os.path.join(save_dir, \"results_fold_data2_org.csv\"), index=False)\n",
    "\n",
    "print(\"Training and evaluation completed. Results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define paths\n",
    "# data_dir = \"data/m_rock_expansion/save/distdiff_batch_3x\"\n",
    "data_dir = \"data/rock_minerals_expansion/save/distdiff_batch_3x(0.2)\"\n",
    "save_dir = \"figure\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset\n",
    "train_dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "# KFold cross-validation setup\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Model definitions\n",
    "models_dict = {\n",
    "    \"ResNet50\": models.resnet50,\n",
    "    \"ResNeXt-50\": models.resnext50_32x4d,\n",
    "    \"WideResNet-50\": models.wide_resnet50_2,\n",
    "    \"MobileNetv2\": models.mobilenet_v2\n",
    "}\n",
    "\n",
    "# Results storage\n",
    "results = []\n",
    "\n",
    "# Training and evaluation function\n",
    "def train_and_evaluate(model_name, model, train_loader, test_loader):\n",
    "    print(f\"Training {model_name}...\")\n",
    "    \n",
    "    # Initialize model, loss, and optimizer\n",
    "    model = model(num_classes=len(train_dataset.classes))  # Correct this line\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(all_labels, all_preds, target_names=train_dataset.classes, output_dict=True)\n",
    "    accuracy = report['accuracy']\n",
    "    recall = np.mean([v['recall'] for k, v in report.items() if k not in ('accuracy', 'macro avg', 'weighted avg')])\n",
    "    f1 = np.mean([v['f1-score'] for k, v in report.items() if k not in ('accuracy', 'macro avg', 'weighted avg')])\n",
    "\n",
    "    print(f\"{model_name} - Accuracy: {accuracy:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "\n",
    "    return accuracy, recall, f1\n",
    "\n",
    "# Cross-validation loop\n",
    "for model_name, model_fn in models_dict.items():\n",
    "    fold_results = []\n",
    "\n",
    "    # Perform KFold cross-validation\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
    "        print(f\"\\nFold {fold+1} - Model: {model_name}\")\n",
    "\n",
    "        # Create data loaders for the current fold\n",
    "        train_subset = Subset(train_dataset, train_idx)\n",
    "        val_subset = Subset(train_dataset, val_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Train and evaluate the model\n",
    "        accuracy, recall, f1 = train_and_evaluate(model_name, model_fn, train_loader, val_loader)\n",
    "        fold_results.append({\n",
    "            'Fold': fold + 1,\n",
    "            'Accuracy': accuracy,\n",
    "            'Recall': recall,\n",
    "            'F1-Score': f1\n",
    "        })\n",
    "\n",
    "    # Calculate average results for the model across all folds\n",
    "    avg_accuracy = np.mean([result['Accuracy'] for result in fold_results])\n",
    "    avg_recall = np.mean([result['Recall'] for result in fold_results])\n",
    "    avg_f1 = np.mean([result['F1-Score'] for result in fold_results])\n",
    "\n",
    "    print(f\"\\n{model_name} - Average Accuracy: {avg_accuracy:.4f}, Average Recall: {avg_recall:.4f}, Average F1-score: {avg_f1:.4f}\")\n",
    "\n",
    "    # Save fold results to the overall results list\n",
    "    for result in fold_results:\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Fold': result['Fold'],\n",
    "            'Accuracy': result['Accuracy'],\n",
    "            'Recall': result['Recall'],\n",
    "            'F1-Score': result['F1-Score']\n",
    "        })\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(os.path.join(save_dir, \"results_fold_data2_exp.csv\"), index=False)\n",
    "\n",
    "print(\"Training and evaluation completed. Results saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distdiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
